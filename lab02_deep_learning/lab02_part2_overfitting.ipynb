{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFmOh482SyEF"
   },
   "source": [
    "## Lab 2\n",
    "### Part 2: Dealing with overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjzAuO3oSvsI"
   },
   "source": [
    "Today we work with [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) (*hint: it is available in `torchvision`*).\n",
    "\n",
    "Your goal for today:\n",
    "1. Train a FC (fully-connected) network that achieves >= 0.885 test accuracy.\n",
    "2. Cause considerable overfitting by modifying the network (e.g. increasing the number of network parameters and/or layers) and demonstrate in in the appropriate way (e.g. plot loss and accurasy on train and validation set w.r.t. network complexity).\n",
    "3. Try to deal with overfitting (at least partially) by using regularization techniques (Dropout/Batchnorm/...) and demonstrate the results.\n",
    "\n",
    "__Please, write a small report describing your ideas, tries and achieved results in the end of this file.__\n",
    "\n",
    "*Note*: Tasks 2 and 3 are interrelated, in task 3 your goal is to make the network from task 2 less prone to overfitting. Task 1 is independent from 2 and 3.\n",
    "\n",
    "*Note 2*: We recomment to use Google Colab or other machine with GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_KBld6VOSwhW"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_output\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchsummary\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdLOG0XqS_g5",
    "outputId": "21662029-93a6-4257-a281-448fab84a378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory fmnist already exists!\n"
     ]
    }
   ],
   "source": [
    "# Technical function\n",
    "def mkdir(path):\n",
    "    if not os.path.exists(root_path):\n",
    "        os.mkdir(root_path)\n",
    "        print('Directory', path, 'is created!')\n",
    "    else:\n",
    "        print('Directory', path, 'already exists!')\n",
    "\n",
    "root_path = 'fmnist'\n",
    "mkdir(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "qt6LE7XaTDT9"
   },
   "outputs": [],
   "source": [
    "download = True\n",
    "train_transform = transforms.ToTensor()\n",
    "test_transform = transforms.ToTensor()\n",
    "transforms.Compose((transforms.ToTensor()))\n",
    "\n",
    "\n",
    "fmnist_dataset_train = torchvision.datasets.FashionMNIST(root_path,\n",
    "                                                        train=True,\n",
    "                                                        transform=train_transform,\n",
    "                                                        target_transform=None,\n",
    "                                                        download=download)\n",
    "fmnist_dataset_test = torchvision.datasets.FashionMNIST(root_path,\n",
    "                                                       train=False,\n",
    "                                                       transform=test_transform,\n",
    "                                                       target_transform=None,\n",
    "                                                       download=download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "71YP0SPwTIxD"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(fmnist_dataset_train,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(fmnist_dataset_test,\n",
    "                                          batch_size=256,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_YFmF7NTWrQ",
    "outputId": "2db57194-8658-45fc-e6ee-4767071b0979"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fmnist_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "ES0CbPj9TwZI",
    "outputId": "9090f1c8-55e5-449d-9cc1-ce520795120d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 0')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_batch = next(iter(train_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f'Image label: {_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHca15bOTY4B",
    "outputId": "c4e1eca9-ef4f-442f-c628-517b62c6de6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "for img, label in train_loader:\n",
    "    print(img.shape)\n",
    "#     print(img)\n",
    "    print(label.shape)\n",
    "    print(label.size(0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6OOOffHTfX5"
   },
   "source": [
    "### Task 1\n",
    "Train a network that achieves $\\geq 0.885$ test accuracy. It's fine to use only Linear (`nn.Linear`) layers and activations/dropout/batchnorm. Convolutional layers might be a great use, but we will meet them a bit later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "ftpkTjxlTcFx"
   },
   "outputs": [],
   "source": [
    "class TinyNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(), # This layer converts image into a vector to use Linear layers afterwards\n",
    "            # Your network structure comes here\n",
    "            nn.Linear(input_shape, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, num_classes),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out = self.model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "DZrIV7X8SjXV",
    "outputId": "65da9e5d-c2a2-4861-863e-46e98a9009df"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-7f70dc05edbd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorchsummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTinyNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-69-24f7c3bc2a46>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1566\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m                 for hook_id, hook in (\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(TinyNeuralNetwork().to(device), (28*28,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "544PGKEnjPr5"
   },
   "source": [
    "Your experiments come here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "i3POFj90Ti-6"
   },
   "outputs": [],
   "source": [
    "model = TinyNeuralNetwork().to(device)\n",
    "opt = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Your experiments, training and validation loops here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "0WYVwXYiUeL8"
   },
   "outputs": [],
   "source": [
    "def train(net, trainloader, criterion, optimizer, epochs=5):\n",
    "    data_len = len(trainloader)\n",
    "    p_len = data_len // 5\n",
    "    for epoch in (range(epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % p_len == p_len - 1:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / p_len:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "jUnZlmZtUfvy",
    "outputId": "8f84ffa8-3bae-4063-e782-a37ab1691963"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-1f1765bb3adb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-33bbc4d827a3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-5366257f9a1e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, loss_func, opt, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7ISqkjmCPB1"
   },
   "source": [
    "### Task 2: Overfit it.\n",
    "Build a network that will overfit to this dataset. Demonstrate the overfitting in the appropriate way (e.g. plot loss and accurasy on train and test set w.r.t. network complexity).\n",
    "\n",
    "*Note:* you also might decrease the size of `train` dataset to enforce the overfitting and speed up the computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H12uAWiGBwJx"
   },
   "outputs": [],
   "source": [
    "class OverfittingNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(), # This layer converts image into a vector to use Linear layers afterwards\n",
    "            # Your network structure comes here\n",
    "            nn.Linear(input_shape, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out = self.model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgXAKCpvCwqH"
   },
   "outputs": [],
   "source": [
    "torchsummary.summary(OverfittingNeuralNetwork().to(device), (28*28,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bguBvfhNSjXY"
   },
   "outputs": [],
   "source": [
    "model = OverfittingNeuralNetwork().to(device)\n",
    "opt = # YOUR CODE HERE\n",
    "loss_func = # YOUR CODE HERE\n",
    "\n",
    "# Your experiments, come here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4Jv6T9oSjXY"
   },
   "source": [
    "### Task 3: Fix it.\n",
    "Fix the overfitted network from the previous step (at least partially) by using regularization techniques (Dropout/Batchnorm/...) and demonstrate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jrod66qSjXY"
   },
   "outputs": [],
   "source": [
    "class FixedNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_shape=28*28, num_classes=10, input_channels=1):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(), # This layer converts image into a vector to use Linear layers afterwards\n",
    "            # Your network structure comes here\n",
    "            nn.Linear(input_shape, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out = self.model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbH1z4sFSjXZ"
   },
   "outputs": [],
   "source": [
    "torchsummary.summary(FixedNeuralNetwork().to(device), (28*28,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljfSX1G_SjXZ"
   },
   "outputs": [],
   "source": [
    "model = FixedNeuralNetwork().to(device)\n",
    "opt = # YOUR CODE HERE\n",
    "loss_func = # YOUR CODE HERE\n",
    "\n",
    "# Your experiments, come here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMui_uLJ7G0d"
   },
   "source": [
    "### Conclusions:\n",
    "_Write down small report with your conclusions and your ideas._"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
